{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc67871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.signal import kaiser,kaiser_beta\n",
    "#from mpmath import *\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "#import h5py   \n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "from lisaconstants import GM_SUN,c,ASTRONOMICAL_YEAR,ASTRONOMICAL_UNIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1f946",
   "metadata": {},
   "source": [
    "# Backwards difference operators function for LISA interferometer measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b692225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_operator_powers(data):\n",
    "\n",
    "    difference_coefficients = np.zeros((number_n+1,length))\n",
    "    difference_coefficients[0] = data\n",
    "    #delta_one = np.roll(data,1)\n",
    "    #delta_one[0] = 0.0\n",
    "    #difference_coefficients[1] = data-delta_one\n",
    "    \n",
    "    for i in np.arange(1,number_n+1):\n",
    "        sum_for_this_power = np.zeros(length)\n",
    "        for j in np.arange(i+1):\n",
    "\n",
    "            data_rolled = np.roll(data,j)\n",
    "            data_rolled[:j] = 0.0\n",
    "\n",
    "            sum_for_this_power = sum_for_this_power + (-1)**j*math.comb(i, j)*data_rolled\n",
    "\n",
    "        difference_coefficients[i] = sum_for_this_power/np.math.factorial(i)\n",
    "\n",
    "    return difference_coefficients.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c93734",
   "metadata": {},
   "source": [
    "# Delay Polynomials Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a774970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filters_lagrange_2_0(D):\n",
    "\n",
    "    #start_time = time.process_time()\n",
    "    D=D*f_samp\n",
    "    integer_part, d_frac = np.divmod(D,1)\n",
    "\n",
    "    integer_part = integer_part-p\n",
    "    d_frac = d_frac+p\n",
    "\n",
    "    delay_polynomials = np.ones((number_n+1,length))\n",
    "\n",
    "    #factors = np.array([-1*d_frac+i for i in ints])\n",
    "    factors = -1*d_frac+ints\n",
    "\n",
    "    delay_polynomials[1:number_n+1] = np.cumprod(factors,axis=0)\n",
    "    #print(\"--- %s seconds for filters lagrange---\" % (time.process_time() - start_time))\n",
    "\n",
    "    return delay_polynomials,int(integer_part[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157582",
   "metadata": {},
   "source": [
    "# The Final FDI filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43829d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_data(data,filter_array):\n",
    "\n",
    "    return np.einsum('ij,ji->i',np.concatenate((np.zeros((filter_array[1],number_n+1)),data),axis=0)[:-filter_array[1]:],filter_array[0],optimize=einsum_path_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f3c56",
   "metadata": {},
   "source": [
    "# Secondary Noise PSD Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe889f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_y_proof_mass_new_frac_freq(f):\n",
    "\n",
    "    pm_here =  np.power(2.4e-15,2)*(1+np.power(4.0e-4/f,2))*(1+np.power(f/8.0e-3,4))\n",
    "    return pm_here*np.power(2*np.pi*f*c,-2)\n",
    "\n",
    "\n",
    "\n",
    "def S_y_OMS_frac_freq(f):\n",
    "\n",
    "    op_here =  np.power(1.5e-11,2)*np.power(2*np.pi*f/c,2)*(1+np.power(2.0e-3/f,4))\n",
    "    return op_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b6a7c",
   "metadata": {},
   "source": [
    "# Functions for $L_{ij}(t)$ in Keplerian Parameterization for Keplerian Orbit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fb1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(k):\n",
    "    return 2.0*np.pi*(k-1)/3\n",
    "\n",
    "\n",
    "def psi(m_init1,eccentricity,orbital_freq,k,t):\n",
    "    m = m_init1 + orbital_freq*(t-t_init) - theta(k)\n",
    "    psi_return = m + (eccentricity-np.power(eccentricity,3)/8)*np.sin(m) + 0.5*eccentricity**2*np.sin(2*m)        + 3.0/8 *np.power(eccentricity,3)*np.sin(3*m)\n",
    "    for i in np.arange(2):\n",
    "        error =psi_return - eccentricity * np.sin(psi_return) - m\n",
    "        psi_return -= error / (1 - eccentricity * np.cos(psi_return)) \n",
    "\n",
    "    return psi_return\n",
    "\n",
    "def orbital_parameters(semi_major):\n",
    "    alpha = L_arm/(2.0*semi_major)\n",
    "    nu = np.pi/3 + delta*alpha\n",
    "    eccentricity = np.sqrt(1 + 4.0*alpha*np.cos(nu)/np.sqrt(3) + 4.0*alpha**2/3) - 1\n",
    "\n",
    "    orbital_freq=np.sqrt(GM_SUN/semi_major**3)\n",
    "\n",
    "    tan_inclination = alpha*np.sin(nu)/(np.sqrt(3.0)/2.0 + alpha*np.cos(nu))\n",
    "    cos_inclination = 1 / np.sqrt(1 + tan_inclination**2)\n",
    "    sin_inclination = tan_inclination*cos_inclination\n",
    "\n",
    "    return alpha,nu,eccentricity,orbital_freq,cos_inclination,sin_inclination\n",
    "\n",
    "\n",
    "\n",
    "def s_c_positions(psi_here,eccentricity,cos_inclination,sin_inclination,semi_major,Omega_1,arg_per,k):\n",
    "    omega = Omega_1+theta(k)\n",
    "\n",
    "    zeta_t = semi_major*(np.cos(psi_here) - eccentricity)\n",
    "    eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.sin(psi_here)\n",
    "    positions = np.empty((3,length))\n",
    "\n",
    "    positions[0] = (np.cos(omega)*np.cos(arg_per) - np.sin(omega)*np.sin(arg_per)*cos_inclination)*zeta_t - (np.cos(omega)*np.sin(arg_per) + np.sin(omega)*np.cos(arg_per)*cos_inclination)*eta_t #x(t)\n",
    "    positions[1] = (np.sin(omega)*np.cos(arg_per) + np.cos(omega)*np.sin(arg_per)*cos_inclination)*zeta_t - (np.sin(omega)*np.sin(arg_per) - np.cos(omega)*np.cos(arg_per)*cos_inclination)*eta_t #y(t)\n",
    "    positions[2] = np.sin(arg_per)*sin_inclination*zeta_t + np.cos(arg_per)*sin_inclination*eta_t #z(t)\n",
    "\n",
    "    return positions\n",
    "\n",
    "def s_c_velocities(psi_here,eccentricity,cos_inclination,sin_inclination,semi_major,orbital_freq,Omega_1,arg_per,k):\n",
    "\n",
    "\n",
    "    psi_dot = orbital_freq/(1.0-eccentricity*np.cos(psi_here))\n",
    "\n",
    "    omega = Omega_1+theta(k)\n",
    "    zeta_t = semi_major*(np.cos(psi_here) - eccentricity)\n",
    "    d_zeta_t = -1*semi_major*np.sin(psi_here)*psi_dot\n",
    "    eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.sin(psi_here)\n",
    "    d_eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.cos(psi_here)*psi_dot\n",
    "    velocities = np.empty((3,length))\n",
    "\n",
    "    velocities[0] = (np.cos(omega)*np.cos(arg_per) - np.sin(omega)*np.sin(arg_per)*cos_inclination)*d_zeta_t - (np.cos(omega)*np.sin(arg_per) + np.sin(omega)*np.cos(arg_per)*cos_inclination)*d_eta_t #x(t)\n",
    "    velocities[1] = (np.sin(omega)*np.cos(arg_per) + np.cos(omega)*np.sin(arg_per)*cos_inclination)*d_zeta_t - (np.sin(omega)*np.sin(arg_per) - np.cos(omega)*np.cos(arg_per)*cos_inclination)*d_eta_t #y(t)\n",
    "    velocities[2] = np.sin(arg_per)*sin_inclination*d_zeta_t + np.cos(arg_per)*sin_inclination*d_eta_t #z(t)\n",
    "\n",
    "    return velocities\n",
    "\n",
    "\n",
    "def s_c_accelerations(position_here,semi_major,orbital_freq):\n",
    "    \n",
    "    return -1*np.power(semi_major,3)*orbital_freq**2*position_here/np.power(np.sqrt(position_here[0]**2+position_here[1]**2+position_here[2]**2),3)\n",
    "\n",
    "\n",
    "def shapiro(pos_i,pos_j):\n",
    "\n",
    "    mag_pos_j = np.sqrt(pos_j[0]**2+pos_j[1]**2+pos_j[2]**2)     \n",
    "    mag_pos_i = np.sqrt(pos_i[0]**2+pos_i[1]**2+pos_i[2]**2)    \n",
    "    diff = pos_j-pos_i\n",
    "    mag_diff = np.sqrt(diff[0]**2 + diff[1]**2 + diff[2]**2)\n",
    "\n",
    "    return 2*GM_SUN/(c**2)*np.log((mag_pos_j + mag_pos_i + mag_diff)/(mag_pos_j+mag_pos_i-mag_diff))\n",
    "\n",
    "def delta_tau(psi_here,m_init1,eccentricity,orbital_freq,semi_major,k,t):\n",
    "    psi_here_init = psi(m_init1,eccentricity,orbital_freq,k,t_init)\n",
    "\n",
    "    return -3.0/2.0*(orbital_freq*semi_major/c)**2*(t-t_init) - 2*(orbital_freq*semi_major/c)**2*eccentricity/orbital_freq*(np.sin(psi_here)-np.sin(psi_here_init))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5df3bf",
   "metadata": {},
   "source": [
    "# Putting all the above functions together for final $L_{ij}(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a647dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dependence(m_init1,semi_major,arg_per):\n",
    "\n",
    "\n",
    "    delay_in_time = np.empty((6,length))\n",
    "    if is_tcb==False:\n",
    "        mprs = np.empty((6,length))\n",
    "\n",
    "    alpha,nu,eccentricity,orbital_freq,cos_inclination,sin_inclination = orbital_parameters(semi_major)\n",
    "    for i,k,z in zip(np.arange(6),np.array([2,3,3,1,1,2]),np.array([3,2,1,3,2,1])):\n",
    "        psi_i = psi(m_init1,eccentricity,orbital_freq,z,tcb_times[z-1])\n",
    "        psi_j = psi(m_init1,eccentricity,orbital_freq,k,tcb_times[z-1])\n",
    "        position_i = s_c_positions(psi_i,eccentricity,cos_inclination,sin_inclination,semi_major,Omega_1,arg_per,z)\n",
    "        position_j = s_c_positions(psi_j,eccentricity,cos_inclination,sin_inclination,semi_major,Omega_1,arg_per,k)\n",
    "        Dij = position_i-position_j\n",
    "\n",
    "\n",
    "        magDij = np.sqrt(Dij[0]**2+Dij[1]**2+Dij[2]**2)\n",
    "\n",
    "        velocity_j = s_c_velocities(psi_j,eccentricity,cos_inclination,sin_inclination,semi_major,orbital_freq,Omega_1,arg_per,k)\n",
    "        second_term = np.sum(Dij*velocity_j,axis=0)/(c**2)\n",
    "\n",
    "        third_term = magDij/(2*np.power(c,3))*(np.sqrt(velocity_j[0]**2+velocity_j[1]**2+velocity_j[2]**2)**2 + np.power(np.sum(velocity_j*Dij,axis=0)/magDij,2) -np.sum(s_c_accelerations(position_j,semi_major,orbital_freq)*Dij,axis=0))\n",
    "\n",
    "        delay_in_time[i] = magDij/c + second_term + third_term +  shapiro(position_i,position_j)/c\n",
    "        if is_tcb==False:\n",
    "            mprs[i] = delay_in_time[i]+ delta_tau(psi_i,m_init1,eccentricity,orbital_freq,semi_major,z,tcb_times[z-1]) - delta_tau(psi_j,m_init1,eccentricity,orbital_freq,semi_major,k,tcb_times[z-1] - delay_in_time[i])\n",
    "\n",
    "\n",
    "    if is_tcb==True:\n",
    "        return delay_in_time\n",
    "    else:\n",
    "        return mprs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f6aca",
   "metadata": {},
   "source": [
    "# For each unique nested delay, generate the three quantities needed for it in TDI equation. (For $\\mathcal{D}_{ij}\\mathcal{D}_{mn}f(t)$: sum of all delays in the sequence $L_{ij},L_{mn}$ as columns, derivative of all delays in the sequence, $\\dot{L}_{ij},\\dot{L}_{mn}$ as columns, correction factor = $L_{ij}\\dot{L}_{mn}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f96702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_delay_application(delay_array_here,list_delays):\n",
    "    number_delays = len(list_delays)\n",
    "    \n",
    "    delays = np.array([delay_array_here[j] for j in list_delays])\n",
    "\n",
    "\n",
    "    delay_dot_array_here = np.gradient(delays,1/f_s,axis=1)\n",
    "\n",
    "    correction_factor =np.zeros(length)\n",
    "\n",
    "    for i in np.arange(number_delays):\n",
    "        for j in np.arange(i+1,number_delays):\n",
    "\n",
    "            correction_factor+=delays[i]*delay_dot_array_here[j]          \n",
    "\n",
    "\n",
    "    doppler_factor = np.sum(delay_dot_array_here,axis=0)\n",
    "\n",
    "    commutative_sum = np.sum(delays,axis=0)\n",
    "\n",
    "    return commutative_sum, np.gradient(commutative_sum,1/f_s), correction_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba08d1",
   "metadata": {},
   "source": [
    "# TDI X Channel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2ee3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_combo_2_0(delay_array):\n",
    "\n",
    "\n",
    "    L12 = nested_delay_application(delay_array,np.array([5]))\n",
    "    L12_L21 = nested_delay_application(delay_array,np.array([5,4]))\n",
    "    L12_L21_L13 = nested_delay_application(delay_array,np.array([5,4,2]))\n",
    "    L12_L21_L13_L31 = nested_delay_application(delay_array,np.array([5,4,2,3]))\n",
    "    L12_L21_L13_L31_L13 = nested_delay_application(delay_array,np.array([5,4,2,3,2]))\n",
    "    L12_L21_L13_L31_L13_L31 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3]))\n",
    "    L12_L21_L13_L31_L13_L31_L12 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3,5]))\n",
    "    L12_L21_L13_L31_L13_L31_L12_L21 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3,5,4]))\n",
    "\n",
    "    L13 = nested_delay_application(delay_array,np.array([2]))\n",
    "    L13_L31 = nested_delay_application(delay_array,np.array([2,3]))\n",
    "    L13_L31_L12 = nested_delay_application(delay_array,np.array([2,3,5]))\n",
    "    L13_L31_L12_L21 = nested_delay_application(delay_array,np.array([2,3,5,4]))\n",
    "    L13_L31_L12_L21_L12 = nested_delay_application(delay_array,np.array([2,3,5,4,5]))\n",
    "    L13_L31_L12_L21_L12_L21 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4]))\n",
    "    L13_L31_L12_L21_L12_L21_L13 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4,2]))\n",
    "    L13_L31_L12_L21_L12_L21_L13_L31 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4,2,3]))\n",
    "\n",
    "    filter_L12 = filters_lagrange_2_0(L12[0])\n",
    "    filter_L12_L21 = filters_lagrange_2_0(L12_L21[0])\n",
    "    filter_L12_L21_L13 = filters_lagrange_2_0(L12_L21_L13[0])\n",
    "    filter_L12_L21_L13_L31 = filters_lagrange_2_0(L12_L21_L13_L31[0])\n",
    "    filter_L12_L21_L13_L31_L13 = filters_lagrange_2_0(L12_L21_L13_L31_L13[0])\n",
    "    filter_L12_L21_L13_L31_L13_L31 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31[0])\n",
    "    filter_L12_L21_L13_L31_L13_L31_L12 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31_L12[0])    \n",
    "    filter_L12_L21_L13_L31_L13_L31_L12_L21 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31_L12_L21[0])\n",
    "\n",
    "    filter_L13 = filters_lagrange_2_0(L13[0])\n",
    "    filter_L13_L31 = filters_lagrange_2_0(L13_L31[0])\n",
    "    filter_L13_L31_L12 = filters_lagrange_2_0(L13_L31_L12[0])\n",
    "    filter_L13_L31_L12_L21 = filters_lagrange_2_0(L13_L31_L12_L21[0])\n",
    "    filter_L13_L31_L12_L21_L12 = filters_lagrange_2_0(L13_L31_L12_L21_L12[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21_L13 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21_L13[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21_L13_L31 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21_L13_L31[0])\n",
    "\n",
    "    x_combo = np.zeros(length)\n",
    "    x_combo = x_combo + (s12 + 0.5*(tau12-eps12)) \n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L12) \n",
    "    x_combo = x_combo + ((1-L12[1])*(next_term + np.gradient(next_term,1/f_s)*L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s13_coeffs + 0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau12_coeffs-tau13_coeffs),filter_L12_L21) \n",
    "    x_combo = x_combo + ((1-L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L12_L21_L13) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L12_L21_L13_L31) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L12_L21_L13_L31_L13) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L12_L21_L13_L31_L13_L31) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L12_L21_L13_L31_L13_L31_L12) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31_L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs),filter_L12_L21_L13_L31_L13_L31_L12_L21) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31_L12_L21[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    x_combo_minus = np.zeros(length)\n",
    "\n",
    "    x_combo_minus = x_combo_minus + (s13 + 0.5*(tau13-eps13) + 0.5*(tau12-tau13)) \n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L13) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13[1])*(next_term + np.gradient(next_term,1/f_s)*L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L13_L31) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L13_L31_L12) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L13_L31_L12_L21) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L13_L31_L12_L21_L12) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s13_coeffs + 0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau12_coeffs-tau13_coeffs),filter_L13_L31_L12_L21_L12_L21) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L13_L31_L12_L21_L12_L21_L13) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs),filter_L13_L31_L12_L21_L12_L21_L13_L31) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21_L13_L31[2]))\n",
    "\n",
    "    x_combo = x_combo - x_combo_minus\n",
    "    '''\n",
    "    #np.savetxt('x_combo_full.dat',x_combo)\n",
    "    plt.plot(s31,label = 's31')\n",
    "    plt.plot(x_combo,label='x combo')\n",
    "    plt.plot(window*x_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    x_f = np.fft.rfft(window*x_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(x_f),np.imag(x_f)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4cba1e",
   "metadata": {},
   "source": [
    "# TDI Y Channel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9f1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_combo_2_0(delay_array):\n",
    "\n",
    "    L23 = nested_delay_application(delay_array,np.array([1]))\n",
    "    L23_L32 = nested_delay_application(delay_array,np.array([1,0]))\n",
    "    L23_L32_L21 = nested_delay_application(delay_array,np.array([1,0,4]))\n",
    "    L23_L32_L21_L12 = nested_delay_application(delay_array,np.array([1,0,4,5]))\n",
    "    L23_L32_L21_L12_L21 = nested_delay_application(delay_array,np.array([1,0,4,5,4]))\n",
    "    L23_L32_L21_L12_L21_L12 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5]))\n",
    "    L23_L32_L21_L12_L21_L12_L23 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5,1]))\n",
    "    L23_L32_L21_L12_L21_L12_L23_L32 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5,1,0]))\n",
    "\n",
    "    L21 = nested_delay_application(delay_array,np.array([4]))\n",
    "    L21_L12 = nested_delay_application(delay_array,np.array([4,5]))\n",
    "    L21_L12_L23 = nested_delay_application(delay_array,np.array([4,5,1]))\n",
    "    L21_L12_L23_L32 = nested_delay_application(delay_array,np.array([4,5,1,0]))\n",
    "    L21_L12_L23_L32_L23 = nested_delay_application(delay_array,np.array([4,5,1,0,1]))\n",
    "    L21_L12_L23_L32_L23_L32 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0]))\n",
    "    L21_L12_L23_L32_L23_L32_L21 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0,4]))\n",
    "    L21_L12_L23_L32_L23_L32_L21_L12 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0,4,5]))\n",
    "\n",
    "\n",
    "    filter_L23 = filters_lagrange_2_0(L23[0])\n",
    "    filter_L23_L32 = filters_lagrange_2_0(L23_L32[0])\n",
    "    filter_L23_L32_L21 = filters_lagrange_2_0(L23_L32_L21[0])\n",
    "    filter_L23_L32_L21_L12 = filters_lagrange_2_0(L23_L32_L21_L12[0])\n",
    "    filter_L23_L32_L21_L12_L21 = filters_lagrange_2_0(L23_L32_L21_L12_L21[0])\n",
    "    filter_L23_L32_L21_L12_L21_L12 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12[0])\n",
    "    filter_L23_L32_L21_L12_L21_L12_L23 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12_L23[0])    \n",
    "    filter_L23_L32_L21_L12_L21_L12_L23_L32 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12_L23_L32[0])\n",
    "\n",
    "    filter_L21 = filters_lagrange_2_0(L21[0])\n",
    "    filter_L21_L12 = filters_lagrange_2_0(L21_L12[0])\n",
    "    filter_L21_L12_L23 = filters_lagrange_2_0(L21_L12_L23[0])\n",
    "    filter_L21_L12_L23_L32 = filters_lagrange_2_0(L21_L12_L23_L32[0])\n",
    "    filter_L21_L12_L23_L32_L23 = filters_lagrange_2_0(L21_L12_L23_L32_L23[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32_L21 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32_L21[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32_L21_L12 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32_L21_L12[0])\n",
    "\n",
    "    y_combo = np.zeros(length)\n",
    "    y_combo = y_combo + (s23 + 0.5*(tau23-eps23)) \n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L23) \n",
    "    y_combo = y_combo + ((1-L23[1])*(next_term + np.gradient(next_term,1/f_s)*L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s21_coeffs + 0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau23_coeffs-tau21_coeffs),filter_L23_L32) \n",
    "    y_combo = y_combo + ((1-L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L23_L32_L21) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L23_L32_L21_L12) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L23_L32_L21_L12_L21) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L23_L32_L21_L12_L21_L12) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L23_L32_L21_L12_L21_L12_L23) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12_L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs),filter_L23_L32_L21_L12_L21_L12_L23_L32) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12_L23_L32[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    y_combo_minus = np.zeros(length)\n",
    "\n",
    "    y_combo_minus = y_combo_minus + (s21 + 0.5*(tau21-eps21) + 0.5*(tau23-tau21)) \n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L21) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21[1])*(next_term + np.gradient(next_term,1/f_s)*L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L21_L12) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L21_L12_L23) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L21_L12_L23_L32) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L21_L12_L23_L32_L23) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s21_coeffs + 0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau23_coeffs-tau21_coeffs),filter_L21_L12_L23_L32_L23_L32) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L21_L12_L23_L32_L23_L32_L21) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs),filter_L21_L12_L23_L32_L23_L32_L21_L12) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32_L21_L12[2]))\n",
    "\n",
    "    y_combo = y_combo - y_combo_minus\n",
    "    \n",
    "    '''\n",
    "    #np.savetxt('y_combo_full.dat',y_combo)\n",
    "    plt.plot(s12,label = 's12_')\n",
    "    plt.plot(y_combo,label='y combo')\n",
    "    plt.plot(window*y_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    y_f = np.fft.rfft(window*y_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(y_f),np.imag(y_f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6b01c",
   "metadata": {},
   "source": [
    "# TDI Z Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62a6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_combo_2_0(delay_array):\n",
    "\n",
    "    L31 = nested_delay_application(delay_array,np.array([3]))\n",
    "    L31_L13 = nested_delay_application(delay_array,np.array([3,2]))\n",
    "    L31_L13_L32 = nested_delay_application(delay_array,np.array([3,2,0]))\n",
    "    L31_L13_L32_L23 = nested_delay_application(delay_array,np.array([3,2,0,1]))\n",
    "    L31_L13_L32_L23_L32 = nested_delay_application(delay_array,np.array([3,2,0,1,0]))\n",
    "    L31_L13_L32_L23_L32_L23 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1]))\n",
    "    L31_L13_L32_L23_L32_L23_L31 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1,3]))\n",
    "    L31_L13_L32_L23_L32_L23_L31_L13 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1,3,2]))\n",
    "\n",
    "    L32 = nested_delay_application(delay_array,np.array([0]))\n",
    "    L32_L23 = nested_delay_application(delay_array,np.array([0,1]))\n",
    "    L32_L23_L31 = nested_delay_application(delay_array,np.array([0,1,3]))\n",
    "    L32_L23_L31_L13 = nested_delay_application(delay_array,np.array([0,1,3,2]))\n",
    "    L32_L23_L31_L13_L31 = nested_delay_application(delay_array,np.array([0,1,3,2,3]))\n",
    "    L32_L23_L31_L13_L31_L13 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2]))\n",
    "    L32_L23_L31_L13_L31_L13_L32 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2,0]))\n",
    "    L32_L23_L31_L13_L31_L13_L32_L23 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2,0,1]))\n",
    "\n",
    "\n",
    "    filter_L31 = filters_lagrange_2_0(L31[0])\n",
    "    filter_L31_L13 = filters_lagrange_2_0(L31_L13[0])\n",
    "    filter_L31_L13_L32 = filters_lagrange_2_0(L31_L13_L32[0])\n",
    "    filter_L31_L13_L32_L23 = filters_lagrange_2_0(L31_L13_L32_L23[0])\n",
    "    filter_L31_L13_L32_L23_L32 = filters_lagrange_2_0(L31_L13_L32_L23_L32[0])\n",
    "    filter_L31_L13_L32_L23_L32_L23 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23[0])\n",
    "    filter_L31_L13_L32_L23_L32_L23_L31 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23_L31[0])    \n",
    "    filter_L31_L13_L32_L23_L32_L23_L31_L13 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23_L31_L13[0])\n",
    "\n",
    "    filter_L32 = filters_lagrange_2_0(L32[0])\n",
    "    filter_L32_L23 = filters_lagrange_2_0(L32_L23[0])\n",
    "    filter_L32_L23_L31 = filters_lagrange_2_0(L32_L23_L31[0])\n",
    "    filter_L32_L23_L31_L13 = filters_lagrange_2_0(L32_L23_L31_L13[0])\n",
    "    filter_L32_L23_L31_L13_L31 = filters_lagrange_2_0(L32_L23_L31_L13_L31[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13_L32 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13_L32[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13_L32_L23 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13_L32_L23[0])\n",
    "\n",
    "        \n",
    "    z_combo = np.zeros(length)\n",
    "    z_combo = z_combo + (s31 + 0.5*(tau31-eps31)) \n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L31) \n",
    "    z_combo = z_combo + ((1-L31[1])*(next_term + np.gradient(next_term,1/f_s)*L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s32_coeffs + 0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau31_coeffs-tau32_coeffs),filter_L31_L13) \n",
    "    z_combo = z_combo + ((1-L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L31_L13_L32) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L31_L13_L32_L23) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L31_L13_L32_L23_L32) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L31_L13_L32_L23_L32_L23) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L31_L13_L32_L23_L32_L23_L31) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23_L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs),filter_L31_L13_L32_L23_L32_L23_L31_L13) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23_L31_L13[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    z_combo_minus = np.zeros(length)\n",
    "\n",
    "    z_combo_minus = z_combo_minus + (s32 + 0.5*(tau32-eps32) + 0.5*(tau31-tau32)) \n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L32) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32[1])*(next_term + np.gradient(next_term,1/f_s)*L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L32_L23) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L32_L23_L31) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L32_L23_L31_L13) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L32_L23_L31_L13_L31) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s32_coeffs + 0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau31_coeffs-tau32_coeffs),filter_L32_L23_L31_L13_L31_L13) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L32_L23_L31_L13_L31_L13_L32) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs),filter_L32_L23_L31_L13_L31_L13_L32_L23) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13_L32_L23[2]))\n",
    "\n",
    "    z_combo = z_combo - z_combo_minus\n",
    "    '''\n",
    "    #np.savetxt('z_combo_full.dat',z_combo)\n",
    "    plt.plot(s12,label = 's12')\n",
    "    plt.plot(z_combo,label='z combo')\n",
    "    plt.plot(window*z_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    z_f = np.fft.rfft(window*z_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(z_f),np.imag(z_f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277f83d",
   "metadata": {},
   "source": [
    "# Equal-arm Noise Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41df3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_equal_arm(f,Sy_OP,Sy_PM):\n",
    "    \n",
    "    a = 16*np.power(np.sin(2*np.pi*f*avg_L),2)*Sy_OP+(8*np.power(np.sin(4*np.pi*f*avg_L),2)+32*np.power(np.sin(2*np.pi*f*avg_L),2))*Sy_PM\n",
    "    b_ = -4*np.sin(2*np.pi*f*avg_L)*np.sin(4*np.pi*f*avg_L)*(4*Sy_PM+Sy_OP)\n",
    "\n",
    "    return 2*a,2*b_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3f814",
   "metadata": {},
   "source": [
    "# $\\log{\\mathcal{L}}$ Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d89c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_analytical_equal_arm(x,y,z):\n",
    "\n",
    "\n",
    "\n",
    "    chi_2 = 1/determinant*(A_*(x[0]**2+x[1]**2+y[0]**2+y[1]**2+z[0]**2+z[1]**2) + 2*B_*(x[0]*y[0]+x[1]*y[1]+x[0]*z[0]+x[1]*z[1]+y[0]*z[0]+y[1]*z[1]))\n",
    "\n",
    "\n",
    "    value = -1*np.sum(chi_2) - log_term_factor - np.sum(log_term_determinant)\n",
    "\n",
    "    return value,np.sum(chi_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad939f6f",
   "metadata": {},
   "source": [
    "# Prior Functions for 3 Keplerian Parameters in Keplerian Orbit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1829fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_minit1(val_minit):\n",
    "    if (val_minit >= low_minit1) and (val_minit <= high_minit1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prior_semi_major(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_semi_major) and (val <= high_semi_major):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def prior_arg_per(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_arg_per) and (val <= high_arg_per):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2423e2a",
   "metadata": {},
   "source": [
    "# $\\log{\\mathcal{L}}*$prior function used with emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d514b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob_fn(state_current):\n",
    "\n",
    "\n",
    "    delays_in_time =time_dependence(state_current[0],state_current[1],state_current[2])\n",
    "\n",
    "\n",
    "    x_combo = x_combo_2_0(delays_in_time)\n",
    "    y_combo = y_combo_2_0(delays_in_time)\n",
    "    z_combo = z_combo_2_0(delays_in_time)\n",
    "\n",
    "    likelihood,chi_2_here = likelihood_analytical_equal_arm(x_combo,y_combo,z_combo)\n",
    "    prior = prior_minit1(state_current[0])*prior_semi_major(state_current[1])*prior_arg_per(state_current[2])\n",
    "\n",
    "    return likelihood + np.log(prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378bb2b",
   "metadata": {},
   "source": [
    "# RUN SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96559434",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_s = 2.0 #sampling rate\n",
    "f_samp = f_s\n",
    "\n",
    "number_n_data = 7 #lagrange filter length\n",
    "number_n = number_n_data\n",
    "p = number_n//2\n",
    "asd_nu = 28.8 # Hz/rtHz\n",
    "\n",
    "\n",
    "\n",
    "f_min = 5.0e-4\n",
    "f_max = 0.03\n",
    "central_freq=281600000000000.0\n",
    "L_arm = 2.5e9\n",
    "avg_L = L_arm/c\n",
    "\n",
    "#Define Orbit Model Used for Data \n",
    "static=False\n",
    "equalarmlength=False\n",
    "keplerian=True\n",
    "\n",
    "\n",
    "matrix=True #Keep this true\n",
    "\n",
    "is_tcb = False #reference frame (SSB (True) or proper psuedo ranges (False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfe9a4",
   "metadata": {},
   "source": [
    "# Defined by Orbit Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9cb3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega_1 = np.pi/2.0\n",
    "delta = 5.0/8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ca3d9",
   "metadata": {},
   "source": [
    "# Initial Parameter Values MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c112813",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_per_0 = -np.pi/2.0\n",
    "semi_major_0=ASTRONOMICAL_UNIT\n",
    "m_init1_0 = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adf247",
   "metadata": {},
   "source": [
    "# Load LISA Instrument Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc484b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "\n",
    "if static==True:\n",
    "    #data =  np.genfromtxt('/Users/jessica/Desktop/Project_2/TDI_2.0/orbit_files/LISA_Instrument_RR_disable_all_but_laser_lock_six_static_orbits_tps_ppr_orbits_pyTDI_size.dat',names=True)\n",
    "    #data =  np.genfromtxt('/Users/jessica/Desktop/Project_2/TDI_2.0/orbit_files/LISA_Instrument_RR_disable_all_but_laser_lock_six_equalarmlength_orbits_tps_ppr_orbits_pyTDI_size.dat',names=True)\n",
    "    data=np.genfromtxt(data_dir+'LISA_Instrument_RR_disable_all_but_laser_lock_six_static_orbits_tps_ppr_orbits_pyTDI_size_mprs_to_file.dat',names=True)\n",
    "\n",
    "elif equalarmlength==True:\n",
    "    data =  np.genfromtxt(data_dir+'LISA_Instrument_RR_disable_all_but_laser_lock_six_equalarmlength_orbits_tps_ppr_orbits_pyTDI_size.dat',names=True)\n",
    "elif keplerian==True:\n",
    "    if is_tcb==True:\n",
    "        data = np.genfromtxt(data_dir+'LISA_Instrument_RR_disable_all_but_laser_lock_six_keplerian_orbits_tcb_ltt_orbits_mprs_and_dpprs_to_file_1_hour_NO_AA_filter_NEW.dat',names=True)\n",
    "    else:\n",
    "        data = np.genfromtxt(data_dir+'LISA_Instrument_Keplerian_orbits_ppr_orbits_2_Hz_86400_sec.dat',names=True)\n",
    "initial_length = len(data['s31'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229f0b6",
   "metadata": {},
   "source": [
    "# NUMBER OF SAMPLES SKIPPED IN YOUR LISA INSTRUMENT SIMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14a5d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 0\n",
    "#cut_off=int(1e4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09819ed7",
   "metadata": {},
   "source": [
    "# $t_i$ for S/C $i \\in \\{1,2,3\\}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f111137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#times = np.arange(initial_length)/f_s\n",
    "times = data['time'][cut_off::]\n",
    "times_one = data['time_one']\n",
    "times_two = data['time_two']\n",
    "times_three = data['time_three']\n",
    "\n",
    "#for LISA Orbits 2.1 \n",
    "'''\n",
    "times = data['time'][cut_off::]\n",
    "times_one = times - data['time_one'][cut_off::]\n",
    "times_two = times - data['time_two'][cut_off::]\n",
    "times_three = times - data['time_three'][cut_off::]\n",
    "'''\n",
    "\n",
    "tcb_times = np.array([times_one,times_two,times_three])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ce2e5",
   "metadata": {},
   "source": [
    "# Important: Check your $t_{init}$ from data simulation with print(i.t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46478e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdbe1d",
   "metadata": {},
   "source": [
    "# Interferometer measurements $s_{ij}(t)$, $\\tau_{ij}(t)$, $\\varepsilon_{ij}(t)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd7915e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s31 = data['s31'][cut_off::]/central_freq\n",
    "s21 = data['s21'][cut_off::]/central_freq\n",
    "s32 = data['s32'][cut_off::]/central_freq\n",
    "s12 = data['s12'][cut_off::]/central_freq\n",
    "s23 = data['s23'][cut_off::]/central_freq\n",
    "s13 = data['s13'][cut_off::]/central_freq\n",
    "\n",
    "\n",
    "tau31 = data['tau31'][cut_off::]/central_freq\n",
    "tau21 = data['tau21'][cut_off::]/central_freq\n",
    "tau12 = data['tau12'][cut_off::]/central_freq\n",
    "tau32 = data['tau32'][cut_off::]/central_freq\n",
    "tau23 = data['tau23'][cut_off::]/central_freq\n",
    "tau13 = data['tau13'][cut_off::]/central_freq\n",
    "\n",
    "eps31 = data['eps31'][cut_off::]/central_freq\n",
    "eps21 = data['eps21'][cut_off::]/central_freq\n",
    "eps12 = data['eps12'][cut_off::]/central_freq\n",
    "eps32 = data['eps32'][cut_off::]/central_freq\n",
    "eps23 = data['eps23'][cut_off::]/central_freq\n",
    "eps13 = data['eps13'][cut_off::]/central_freq\n",
    "\n",
    "\n",
    "\n",
    "length = len(s31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89b7cc",
   "metadata": {},
   "source": [
    "# Required for FDI Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64090d2",
   "metadata": {},
   "source": [
    "## Constant array for calculating delay polynomials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ddd01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = np.broadcast_to(np.arange(number_n),(length,number_n)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a541859",
   "metadata": {},
   "source": [
    "## Coefficients in Lagrange Time-varying Filter (Pre-Processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36794c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "s32_coeffs = difference_operator_powers(s32)\n",
    "s31_coeffs = difference_operator_powers(s31)\n",
    "s12_coeffs = difference_operator_powers(s12)\n",
    "s13_coeffs = difference_operator_powers(s13)\n",
    "s21_coeffs = difference_operator_powers(s21)\n",
    "s23_coeffs = difference_operator_powers(s23)\n",
    "\n",
    "eps32_coeffs = difference_operator_powers(eps32)\n",
    "eps31_coeffs = difference_operator_powers(eps31)\n",
    "eps12_coeffs = difference_operator_powers(eps12)\n",
    "eps13_coeffs = difference_operator_powers(eps13)\n",
    "eps21_coeffs = difference_operator_powers(eps21)\n",
    "eps23_coeffs = difference_operator_powers(eps23)\n",
    "\n",
    "tau32_coeffs = difference_operator_powers(tau32)\n",
    "tau31_coeffs = difference_operator_powers(tau31)\n",
    "tau12_coeffs = difference_operator_powers(tau12)\n",
    "tau13_coeffs = difference_operator_powers(tau13)\n",
    "tau21_coeffs = difference_operator_powers(tau21)\n",
    "tau23_coeffs = difference_operator_powers(tau23)\n",
    "\n",
    "\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294edec",
   "metadata": {},
   "source": [
    "# Constant Quantities for $\\log{\\mathcal{L}}$ Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8a282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data_length = len(s31)\n",
    "\n",
    "\n",
    "window = kaiser(cut_data_length,kaiser_beta(320))\n",
    "\n",
    "f_band = np.fft.rfftfreq(cut_data_length,1/f_s)\n",
    "indices_f_band = np.where(np.logical_and(f_band>=f_min, f_band<=f_max))\n",
    "f_band=f_band[indices_f_band]\n",
    "\n",
    "Sy_PM = S_y_proof_mass_new_frac_freq(f_band)\n",
    "Sy_OP = S_y_OMS_frac_freq(f_band)\n",
    "a,b_ = covariance_equal_arm(f_band,Sy_OP,Sy_PM)\n",
    "\n",
    "#Needed in inverse calculation\n",
    "A_ = a**2 - b_**2\n",
    "B_ = b_**2 - a*b_\n",
    "\n",
    "log_term_factor = 3*np.log(np.pi)\n",
    "determinant = a*A_+2*b_*B_\n",
    "log_term_determinant = np.log(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874bd79",
   "metadata": {},
   "source": [
    "# Uniform Prior Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad515336",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_minit1 = -np.pi/2.0\n",
    "high_minit1 = np.pi/2.0\n",
    "\n",
    "\n",
    "low_semi_major = 1.494e11 # where LISA Constants is 149597870700.0\n",
    "high_semi_major = 1.497e11 #Estimate from Fig 6 Trajectory Design Paper (for 10 years; way conservative)#Estimate from Fig 6 Trajectory Design Paper (for 10 years; way conservative)\n",
    "\n",
    "\n",
    "low_arg_per = -np.pi\n",
    "high_arg_per = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1941a1e",
   "metadata": {},
   "source": [
    "# Get optimal einsum path for FDI trim_data function (Run the einsum path once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52b6a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "einsum_path_to_use\n",
      "['einsum_path', (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "orbital_L_3_p = time_dependence(m_init1_0,semi_major_0,arg_per_0)\n",
    "nested = nested_delay_application(orbital_L_3_p,np.array([0,1]))\n",
    "test_filter = filters_lagrange_2_0(nested[0])\n",
    "data_to_use_s13 = np.concatenate((np.zeros((test_filter[1],number_n+1)),s13_coeffs),axis=0)\n",
    "data_here_s13 = data_to_use_s13[:-test_filter[1]:]   \n",
    "einsum_path_to_use = np.einsum_path('ij,ji->i',data_here_s13,test_filter[0], optimize='True')[0]\n",
    "print('einsum_path_to_use')\n",
    "print(einsum_path_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c112fe",
   "metadata": {},
   "source": [
    "# RUN EMCEE SAMPLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867be1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_state_truth\n",
      "[ 0.00000000e+00  1.49597871e+11 -1.57079633e+00]\n",
      "initial_state\n",
      "[[-9.70754619e-06 -6.85153880e-06 -6.70237886e-06 -9.98318565e-06\n",
      "   3.69106670e-06  1.81009418e-06  4.79802139e-06  2.81704336e-06\n",
      "   5.62282009e-06 -5.77434869e-06]\n",
      " [ 1.49597423e+11  1.49597803e+11  1.49597203e+11  1.49597424e+11\n",
      "   1.49597974e+11  1.49597680e+11  1.49597025e+11  1.49597457e+11\n",
      "   1.49597573e+11  1.49597879e+11]\n",
      " [-1.57079673e+00 -1.57079649e+00 -1.57079665e+00 -1.57079634e+00\n",
      "  -1.57079654e+00 -1.57079656e+00 -1.57079696e+00 -1.57079541e+00\n",
      "  -1.57079548e+00 -1.57079625e+00]]\n",
      "initial_state.T\n",
      "[[-9.70754619e-06  1.49597423e+11 -1.57079673e+00]\n",
      " [-6.85153880e-06  1.49597803e+11 -1.57079649e+00]\n",
      " [-6.70237886e-06  1.49597203e+11 -1.57079665e+00]\n",
      " [-9.98318565e-06  1.49597424e+11 -1.57079634e+00]\n",
      " [ 3.69106670e-06  1.49597974e+11 -1.57079654e+00]\n",
      " [ 1.81009418e-06  1.49597680e+11 -1.57079656e+00]\n",
      " [ 4.79802139e-06  1.49597025e+11 -1.57079696e+00]\n",
      " [ 2.81704336e-06  1.49597457e+11 -1.57079541e+00]\n",
      " [ 5.62282009e-06  1.49597573e+11 -1.57079548e+00]\n",
      " [-5.77434869e-06  1.49597879e+11 -1.57079625e+00]]\n",
      "initial_state appended\n",
      "[[-9.70754619e-06  1.49597423e+11 -1.57079673e+00]\n",
      " [-6.85153880e-06  1.49597803e+11 -1.57079649e+00]\n",
      " [-6.70237886e-06  1.49597203e+11 -1.57079665e+00]\n",
      " [-9.98318565e-06  1.49597424e+11 -1.57079634e+00]\n",
      " [ 3.69106670e-06  1.49597974e+11 -1.57079654e+00]\n",
      " [ 1.81009418e-06  1.49597680e+11 -1.57079656e+00]\n",
      " [ 4.79802139e-06  1.49597025e+11 -1.57079696e+00]\n",
      " [ 2.81704336e-06  1.49597457e+11 -1.57079541e+00]\n",
      " [ 5.62282009e-06  1.49597573e+11 -1.57079548e+00]\n",
      " [-5.77434869e-06  1.49597879e+11 -1.57079625e+00]\n",
      " [ 0.00000000e+00  1.49597871e+11 -1.57079633e+00]]\n",
      "initial_state_truth\n",
      "[ 0.00000000e+00  1.49597871e+11 -1.57079633e+00]\n",
      "ndims\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"<ipython-input-15-8ac04b4aa547>\", line 8, in target_log_prob_fn\n",
      "    y_combo = y_combo_2_0(delays_in_time)\n",
      "  File \"<ipython-input-10-d9f3c0058d92>\", line 27, in y_combo_2_0\n",
      "    filter_L23_L32_L21_L12_L21_L12 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12[0])\n",
      "  File \"<ipython-input-3-3228ab45fb0a>\", line 5, in filters_lagrange_2_0\n",
      "    integer_part, d_frac = np.divmod(D,1)\n",
      "KeyboardInterrupt\n",
      "  0%|          | 0/10000 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:\n",
      "  params: [ 1.99674203e-06  1.49597639e+11 -1.57079659e+00]\n",
      "  args: []\n",
      "  kwargs: {}\n",
      "  exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cda3145f55d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress, progress_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0;31m# Propose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/emcee/moves/red_blue.py\u001b[0m in \u001b[0;36mpropose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Compute the lnprobs of the proposed position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mnew_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Loop over the walkers and update them accordingly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mmap_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-8ac04b4aa547>\u001b[0m in \u001b[0;36mtarget_log_prob_fn\u001b[0;34m(state_current)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx_combo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_combo_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelays_in_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_combo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_combo_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelays_in_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mz_combo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_combo_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelays_in_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d9f3c0058d92>\u001b[0m in \u001b[0;36my_combo_2_0\u001b[0;34m(delay_array)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfilter_L23_L32_L21_L12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters_lagrange_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL23_L32_L21_L12\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfilter_L23_L32_L21_L12_L21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters_lagrange_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL23_L32_L21_L12_L21\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfilter_L23_L32_L21_L12_L21_L12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters_lagrange_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL23_L32_L21_L12_L21_L12\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfilter_L23_L32_L21_L12_L21_L12_L23\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters_lagrange_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL23_L32_L21_L12_L21_L12_L23\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mfilter_L23_L32_L21_L12_L21_L12_L23_L32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters_lagrange_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL23_L32_L21_L12_L21_L12_L23_L32\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3228ab45fb0a>\u001b[0m in \u001b[0;36mfilters_lagrange_2_0\u001b[0;34m(D)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#start_time = time.process_time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf_samp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minteger_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_frac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minteger_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_part\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#time mcmc computation time\n",
    "start_time = time.time()\n",
    "\n",
    "#initial delays accepted into the chain\n",
    "accept = 1\n",
    "initial_delays_in_time = time_dependence(m_init1_0,semi_major_0,arg_per_0)\n",
    "\n",
    "#initial_state_truth = np.array([elements_data[0],elements_data[1],elements_data[2],elements_data[3],elements_data[4],elements_data[5],elements_data[6],elements_data[7],elements_data[8],elements_data[9],elements_data[10],elements_data[11],elements_data[12],elements_data[13],elements_data[14],elements_data[15],elements_data[16],elements_data[17]])\n",
    "initial_state_truth = np.array([m_init1_0,semi_major_0,arg_per_0])\n",
    "print('initial_state_truth')\n",
    "print(initial_state_truth)\n",
    "#ndims = len(initial_state_truth) # number of parameters/dimensions\n",
    "\n",
    "Nens = 10  # number of ensemble points\n",
    "Nburnin = 100   # number of burn-in samples\n",
    "Nsamples = 10000  # number of final posterior samples\n",
    "\n",
    "#initial_state = np.array([np.random.uniform(low_minit1,high_minit1,size=Nens),np.random.uniform(low_semi_major,high_semi_major,size=Nens),np.random.uniform(low_arg_per,high_arg_per,size=Nens)])\n",
    "initial_state = np.array([np.random.uniform(m_init1_0-1.0e-5,m_init1_0+1.0e-5,size=Nens),np.random.uniform(1.49597e+11,1.49598e+11,size=Nens),np.random.uniform(arg_per_0-1.0e-6,arg_per_0+1.0e-6,size=Nens)])\n",
    "print('initial_state')\n",
    "print(initial_state)\n",
    "print('initial_state.T')\n",
    "print(initial_state.T)\n",
    "#sys.exit()\n",
    "initial_state=initial_state.T\n",
    "ndims = initial_state.shape[1]\n",
    "#initial_state = np.append(initial_state,initial_state_truth)\n",
    "\n",
    "initial_state = np.vstack([initial_state, initial_state_truth])\n",
    "print('initial_state appended')\n",
    "print(initial_state)\n",
    "print('initial_state_truth')\n",
    "print(initial_state_truth)\n",
    "Nens+=1\n",
    "\n",
    "ndims = initial_state.shape[1]\n",
    "print('ndims')\n",
    "print(ndims)\n",
    "\n",
    "x_combo_initial_2_0 = x_combo_2_0(initial_delays_in_time)\n",
    "y_combo_initial_2_0 = y_combo_2_0(initial_delays_in_time)\n",
    "z_combo_initial_2_0 = z_combo_2_0(initial_delays_in_time)\n",
    "\n",
    "filename = \"samples_Keplerian_chain_omega_emcee_backend_testing_small_ball.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(Nens, ndims)\n",
    "sampler = emcee.EnsembleSampler(Nens, ndims, target_log_prob_fn,backend=backend)\n",
    "\n",
    "f = open(\"samples_Keplerian_chain_omega_emcee_testing_small_ball.dat\", \"w\")\n",
    "f.close()\n",
    "\n",
    "max_n = Nsamples\n",
    "\n",
    "# We'll track how the average autocorrelation time estimate changes\n",
    "index_here = 0\n",
    "autocorr = np.empty(max_n)\n",
    "\n",
    "# This will be useful to testing convergence\n",
    "old_tau = np.inf\n",
    "\n",
    "\n",
    "\n",
    "for result in sampler.sample(initial_state, iterations=max_n,progress=True):\n",
    "\n",
    "\n",
    "    position = result[0]\n",
    "    f = open(\"samples_Keplerian_chain_omega_emcee_testing_small_ball.dat\", \"a\")\n",
    "    for k in range(position.shape[0]):\n",
    "        f.write(\"{0:4d} {1:s}\\n\".format(k, \" \".join(map(str,position[k]))))\n",
    "    f.close()\n",
    "\n",
    "    if sampler.iteration % 100:\n",
    "        continue\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    autocorr[index_here] = np.mean(tau)\n",
    "    index_here += 1\n",
    "\n",
    "    # Check convergence\n",
    "    converged = np.all(tau * 100 < sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    if converged:\n",
    "        break\n",
    "    old_tau = tau\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) \n",
    "\n",
    "\n",
    "n = 100 * np.arange(1, index_here + 1)\n",
    "y = autocorr[:index_here]\n",
    "plt.plot(n, n / 100.0, \"--k\")\n",
    "plt.plot(n, y)\n",
    "plt.xlim(0, n.max())\n",
    "plt.ylim(0, y.max() + 0.1 * (y.max() - y.min()))\n",
    "plt.xlabel(\"number of steps\")\n",
    "plt.ylabel(r\"mean $\\hat{\\tau}$\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1135ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
