{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.signal import kaiser,kaiser_beta\n",
    "#from mpmath import *\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "#import h5py   \n",
    "import matplotlib.pyplot as plt\n",
    "import zeus\n",
    "from multiprocessing import Pool\n",
    "from lisaconstants import GM_SUN,c,ASTRONOMICAL_YEAR,ASTRONOMICAL_UNIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1f946",
   "metadata": {},
   "source": [
    "# Backwards difference operators function for LISA interferometer measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b692225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_operator_powers(data):\n",
    "\n",
    "    difference_coefficients = np.zeros((number_n+1,length))\n",
    "    difference_coefficients[0] = data\n",
    "    #delta_one = np.roll(data,1)\n",
    "    #delta_one[0] = 0.0\n",
    "    #difference_coefficients[1] = data-delta_one\n",
    "    \n",
    "    for i in np.arange(1,number_n+1):\n",
    "        sum_for_this_power = np.zeros(length)\n",
    "        for j in np.arange(i+1):\n",
    "\n",
    "            data_rolled = np.roll(data,j)\n",
    "            data_rolled[:j] = 0.0\n",
    "\n",
    "            sum_for_this_power = sum_for_this_power + (-1)**j*math.comb(i, j)*data_rolled\n",
    "\n",
    "        difference_coefficients[i] = sum_for_this_power/np.math.factorial(i)\n",
    "\n",
    "    return difference_coefficients.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c93734",
   "metadata": {},
   "source": [
    "# Delay Polynomials Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filters_lagrange_2_0(D):\n",
    "\n",
    "    #start_time = time.process_time()\n",
    "    D=D*f_samp\n",
    "    integer_part, d_frac = np.divmod(D,1)\n",
    "\n",
    "    integer_part = integer_part-p\n",
    "    d_frac = d_frac+p\n",
    "\n",
    "    delay_polynomials = np.ones((number_n+1,length))\n",
    "\n",
    "    #factors = np.array([-1*d_frac+i for i in ints])\n",
    "    factors = -1*d_frac+ints\n",
    "\n",
    "    delay_polynomials[1:number_n+1] = np.cumprod(factors,axis=0)\n",
    "    #print(\"--- %s seconds for filters lagrange---\" % (time.process_time() - start_time))\n",
    "\n",
    "    return delay_polynomials,int(integer_part[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157582",
   "metadata": {},
   "source": [
    "# The Final FDI filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43829d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_data(data,filter_array):\n",
    "\n",
    "    return np.einsum('ij,ji->i',np.concatenate((np.zeros((filter_array[1],number_n+1)),data),axis=0)[:-filter_array[1]:],filter_array[0],optimize=einsum_path_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f3c56",
   "metadata": {},
   "source": [
    "# Secondary Noise PSD Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe889f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_y_proof_mass_new_frac_freq(f):\n",
    "\n",
    "    pm_here =  np.power(2.4e-15,2)*(1+np.power(4.0e-4/f,2))*(1+np.power(f/8.0e-3,4))\n",
    "    return pm_here*np.power(2*np.pi*f*c,-2)\n",
    "\n",
    "\n",
    "\n",
    "def S_y_OMS_frac_freq(f):\n",
    "\n",
    "    op_here =  np.power(1.5e-11,2)*np.power(2*np.pi*f/c,2)*(1+np.power(2.0e-3/f,4))\n",
    "    return op_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b6a7c",
   "metadata": {},
   "source": [
    "# Functions for $L_{ij}(t)$ in Keplerian Parameterization for Keplerian Orbit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(k):\n",
    "    return 2.0*np.pi*(k-1)/3\n",
    "\n",
    "\n",
    "def psi(m_init1,eccentricity,orbital_freq,k,t):\n",
    "    m = m_init1 + orbital_freq*(t-t_init)\n",
    "\n",
    "    psi_return = m + (eccentricity-np.power(eccentricity,3)/8.0)*np.sin(m) + 0.5*eccentricity**2*np.sin(2.0*m)  + 3.0/8*np.power(eccentricity,3)*np.sin(3.0*m)\n",
    "    for i in np.arange(2):\n",
    "        error =psi_return - eccentricity * np.sin(psi_return) - m\n",
    "        psi_return -= error / (1.0 - eccentricity * np.cos(psi_return)) \n",
    "\n",
    "    return psi_return\n",
    " \n",
    "\n",
    "def orbital_parameters(semi_major,inclination):\n",
    "\n",
    "\n",
    "    orbital_freq=np.sqrt(GM_SUN/semi_major**3)\n",
    "\n",
    "    cos_inclination = np.cos(inclination)\n",
    "    sin_inclination = np.sin(inclination)\n",
    "\n",
    "    return orbital_freq,cos_inclination,sin_inclination\n",
    "\n",
    "def s_c_positions(psi_here,eccentricity,cos_inclination,sin_inclination,semi_major,orbital_freq,omega,arg_per,k):\n",
    "\n",
    "    lambda_k = omega  + arg_per\n",
    "    zeta_t = semi_major*(np.cos(psi_here) - eccentricity)\n",
    "    eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.sin(psi_here)\n",
    "    positions = np.empty((3,length))\n",
    "\n",
    "    positions[0] = (np.cos(omega)*np.cos(arg_per) - np.sin(omega)*np.sin(arg_per)*cos_inclination)*zeta_t - (np.cos(omega)*np.sin(arg_per) + np.sin(omega)*np.cos(arg_per)*cos_inclination)*eta_t #x(t)\n",
    "    positions[1] = (np.sin(omega)*np.cos(arg_per) + np.cos(omega)*np.sin(arg_per)*cos_inclination)*zeta_t - (np.sin(omega)*np.sin(arg_per) - np.cos(omega)*np.cos(arg_per)*cos_inclination)*eta_t #y(t)\n",
    "    positions[2] = np.sin(arg_per)*sin_inclination*zeta_t + np.cos(arg_per)*sin_inclination*eta_t #z(t)\n",
    "\n",
    "    return positions\n",
    "\n",
    "def s_c_velocities(psi_here,eccentricity,cos_inclination,sin_inclination,semi_major,orbital_freq,omega,arg_per,k):\n",
    "\n",
    "    psi_dot = orbital_freq/(1.0-eccentricity*np.cos(psi_here))\n",
    "\n",
    "    lambda_k = omega  + arg_per\n",
    "    zeta_t = semi_major*(np.cos(psi_here) - eccentricity)\n",
    "    d_zeta_t = -1*semi_major*np.sin(psi_here)*psi_dot\n",
    "    eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.sin(psi_here)\n",
    "    d_eta_t = semi_major*np.sqrt(1.0-eccentricity**2)*np.cos(psi_here)*psi_dot\n",
    "    velocities = np.empty((3,length))\n",
    "\n",
    "    velocities[0] = (np.cos(omega)*np.cos(arg_per) - np.sin(omega)*np.sin(arg_per)*cos_inclination)*d_zeta_t - (np.cos(omega)*np.sin(arg_per) + np.sin(omega)*np.cos(arg_per)*cos_inclination)*d_eta_t #x(t)\n",
    "    velocities[1] = (np.sin(omega)*np.cos(arg_per) + np.cos(omega)*np.sin(arg_per)*cos_inclination)*d_zeta_t - (np.sin(omega)*np.sin(arg_per) - np.cos(omega)*np.cos(arg_per)*cos_inclination)*d_eta_t #y(t)\n",
    "    velocities[2] = np.sin(arg_per)*sin_inclination*d_zeta_t + np.cos(arg_per)*sin_inclination*d_eta_t #z(t)\n",
    "\n",
    "    return velocities\n",
    "\n",
    "def s_c_accelerations(position_here,semi_major,orbital_freq):\n",
    "    \n",
    "    return -1.0*np.power(semi_major,3)*orbital_freq**2*position_here/np.power(np.sqrt(position_here[0]**2+position_here[1]**2+position_here[2]**2),3)\n",
    "\n",
    "def shapiro(pos_i,pos_j):\n",
    "                                                         #/(np.linalg.norm(pos_j,axis=0)+np.linalg.norm(pos_i,axis=0)-np.linalg.norm(pos_j-pos_i,axis=0)))\n",
    "\n",
    "    mag_pos_j = np.sqrt(pos_j[0]**2+pos_j[1]**2+pos_j[2]**2)     \n",
    "    mag_pos_i = np.sqrt(pos_i[0]**2+pos_i[1]**2+pos_i[2]**2)    \n",
    "    diff = pos_j-pos_i\n",
    "    mag_diff = np.sqrt(diff[0]**2 + diff[1]**2 + diff[2]**2)\n",
    "\n",
    "    return 2.0*GM_SUN/(c**2)*np.log((mag_pos_j + mag_pos_i + mag_diff)/(mag_pos_j+mag_pos_i-mag_diff))\n",
    "\n",
    "def delta_tau(psi_here,m_init1,eccentricity,orbital_freq,semi_major,k,t):\n",
    "    \n",
    "    psi_here_init = psi(m_init1,eccentricity,orbital_freq,k,t_init)\n",
    "\n",
    "    return -3.0/2.0*(orbital_freq*semi_major/c)**2*(t-t_init) - 2.0*(orbital_freq*semi_major/c)**2*eccentricity/orbital_freq*(np.sin(psi_here)-np.sin(psi_here_init))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5df3bf",
   "metadata": {},
   "source": [
    "# Putting all the above functions together for final $L_{ij}(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a647dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dependence(m_init1,semi_major,eccentricity,inclination,omega_init,arg_per):\n",
    "\n",
    "\n",
    "    delay_in_time = np.empty((6,length))\n",
    "    if is_tcb==False:\n",
    "        mprs = np.empty((6,length))\n",
    "\n",
    "    orbital_freq,cos_inclination,sin_inclination = orbital_parameters(semi_major,inclination)\n",
    "\n",
    "    for i,k,z in zip(np.arange(6),np.array([2,3,3,1,1,2]),np.array([3,2,1,3,2,1])):\n",
    "        psi_i = psi(m_init1[z-1],eccentricity[z-1],orbital_freq[z-1],z,tcb_times[z-1])\n",
    "        psi_j = psi(m_init1[k-1],eccentricity[k-1],orbital_freq[k-1],k,tcb_times[z-1])\n",
    "\n",
    "        position_i = s_c_positions(psi_i,eccentricity[z-1],cos_inclination[z-1],sin_inclination[z-1],semi_major[z-1],orbital_freq[z-1],omega_init[z-1],arg_per[z-1],z)\n",
    "        position_j = s_c_positions(psi_j,eccentricity[k-1],cos_inclination[k-1],sin_inclination[k-1],semi_major[k-1],orbital_freq[k-1],omega_init[k-1],arg_per[k-1],k)\n",
    "\n",
    "        Dij = position_i-position_j\n",
    "\n",
    "\n",
    "        magDij = np.sqrt(Dij[0]**2+Dij[1]**2+Dij[2]**2)\n",
    "\n",
    "\n",
    "        velocity_j = s_c_velocities(psi_j,eccentricity[k-1],cos_inclination[k-1],sin_inclination[k-1],semi_major[k-1],orbital_freq[k-1],omega_init[k-1],arg_per[k-1],k)\n",
    "\n",
    "        second_term = np.sum(Dij*velocity_j,axis=0)/(c**2)\n",
    "\n",
    "        mag_v_j = np.sqrt(velocity_j[0]**2+velocity_j[1]**2+velocity_j[2]**2)\n",
    "        third_term = magDij/(2.0*np.power(c,3))*(mag_v_j**2 + np.power(np.sum(velocity_j*Dij,axis=0)/magDij,2) -np.sum(s_c_accelerations(position_j,semi_major[k-1],orbital_freq[k-1])*Dij,axis=0))\n",
    "\n",
    "        delay_in_time[i] = magDij/c + second_term + third_term +  shapiro(position_i,position_j)/c\n",
    "\n",
    "        if is_tcb==False:\n",
    "\n",
    "            mprs[i] = delay_in_time[i]+ delta_tau(psi_i,m_init1[z-1],eccentricity[z-1],orbital_freq[z-1],semi_major[z-1],z,tcb_times[z-1]) - delta_tau(psi_j,m_init1[k-1],eccentricity[k-1],orbital_freq[k-1],semi_major[k-1],k,tcb_times[z-1] - delay_in_time[i])\n",
    "\n",
    "    if is_tcb==True:\n",
    "        return delay_in_time\n",
    "    else:\n",
    "        return mprs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f6aca",
   "metadata": {},
   "source": [
    "# For each unique nested delay, generate the three quantities needed for it in TDI equation. (For $\\mathcal{D}_{ij}\\mathcal{D}_{mn}f(t)$: sum of all delays in the sequence $L_{ij},L_{mn}$ as columns, derivative of all delays in the sequence, $\\dot{L}_{ij},\\dot{L}_{mn}$ as columns, correction factor = $L_{ij}\\dot{L}_{mn}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f96702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_delay_application(delay_array_here,list_delays):\n",
    "    number_delays = len(list_delays)\n",
    "    \n",
    "    delays = np.array([delay_array_here[j] for j in list_delays])\n",
    "\n",
    "\n",
    "    delay_dot_array_here = np.gradient(delays,1/f_s,axis=1,edge_order=2)\n",
    "\n",
    "    correction_factor =np.zeros(length)\n",
    "\n",
    "    for i in np.arange(number_delays):\n",
    "        for j in np.arange(i+1,number_delays):\n",
    "\n",
    "            correction_factor+=delays[i]*delay_dot_array_here[j]          \n",
    "\n",
    "\n",
    "    doppler_factor = np.sum(delay_dot_array_here,axis=0)\n",
    "\n",
    "    commutative_sum = np.sum(delays,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return commutative_sum, np.gradient(commutative_sum,1/f_s), correction_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba08d1",
   "metadata": {},
   "source": [
    "# TDI X Channel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ee3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_combo_2_0(delay_array):\n",
    "\n",
    "\n",
    "    L12 = nested_delay_application(delay_array,np.array([5]))\n",
    "    L12_L21 = nested_delay_application(delay_array,np.array([5,4]))\n",
    "    L12_L21_L13 = nested_delay_application(delay_array,np.array([5,4,2]))\n",
    "    L12_L21_L13_L31 = nested_delay_application(delay_array,np.array([5,4,2,3]))\n",
    "    L12_L21_L13_L31_L13 = nested_delay_application(delay_array,np.array([5,4,2,3,2]))\n",
    "    L12_L21_L13_L31_L13_L31 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3]))\n",
    "    L12_L21_L13_L31_L13_L31_L12 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3,5]))\n",
    "    L12_L21_L13_L31_L13_L31_L12_L21 = nested_delay_application(delay_array,np.array([5,4,2,3,2,3,5,4]))\n",
    "\n",
    "    L13 = nested_delay_application(delay_array,np.array([2]))\n",
    "    L13_L31 = nested_delay_application(delay_array,np.array([2,3]))\n",
    "    L13_L31_L12 = nested_delay_application(delay_array,np.array([2,3,5]))\n",
    "    L13_L31_L12_L21 = nested_delay_application(delay_array,np.array([2,3,5,4]))\n",
    "    L13_L31_L12_L21_L12 = nested_delay_application(delay_array,np.array([2,3,5,4,5]))\n",
    "    L13_L31_L12_L21_L12_L21 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4]))\n",
    "    L13_L31_L12_L21_L12_L21_L13 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4,2]))\n",
    "    L13_L31_L12_L21_L12_L21_L13_L31 = nested_delay_application(delay_array,np.array([2,3,5,4,5,4,2,3]))\n",
    "\n",
    "    filter_L12 = filters_lagrange_2_0(L12[0])\n",
    "    filter_L12_L21 = filters_lagrange_2_0(L12_L21[0])\n",
    "    filter_L12_L21_L13 = filters_lagrange_2_0(L12_L21_L13[0])\n",
    "    filter_L12_L21_L13_L31 = filters_lagrange_2_0(L12_L21_L13_L31[0])\n",
    "    filter_L12_L21_L13_L31_L13 = filters_lagrange_2_0(L12_L21_L13_L31_L13[0])\n",
    "    filter_L12_L21_L13_L31_L13_L31 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31[0])\n",
    "    filter_L12_L21_L13_L31_L13_L31_L12 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31_L12[0])    \n",
    "    filter_L12_L21_L13_L31_L13_L31_L12_L21 = filters_lagrange_2_0(L12_L21_L13_L31_L13_L31_L12_L21[0])\n",
    "\n",
    "    filter_L13 = filters_lagrange_2_0(L13[0])\n",
    "    filter_L13_L31 = filters_lagrange_2_0(L13_L31[0])\n",
    "    filter_L13_L31_L12 = filters_lagrange_2_0(L13_L31_L12[0])\n",
    "    filter_L13_L31_L12_L21 = filters_lagrange_2_0(L13_L31_L12_L21[0])\n",
    "    filter_L13_L31_L12_L21_L12 = filters_lagrange_2_0(L13_L31_L12_L21_L12[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21_L13 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21_L13[0])\n",
    "    filter_L13_L31_L12_L21_L12_L21_L13_L31 = filters_lagrange_2_0(L13_L31_L12_L21_L12_L21_L13_L31[0])\n",
    "\n",
    "    x_combo = np.zeros(length)\n",
    "    x_combo = x_combo + (s12 + 0.5*(tau12-eps12)) \n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L12) \n",
    "    x_combo = x_combo + ((1-L12[1])*(next_term + np.gradient(next_term,1/f_s)*L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s13_coeffs + 0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau12_coeffs-tau13_coeffs),filter_L12_L21) \n",
    "    x_combo = x_combo + ((1-L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L12_L21_L13) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L12_L21_L13_L31) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L12_L21_L13_L31_L13) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L12_L21_L13_L31_L13_L31) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L12_L21_L13_L31_L13_L31_L12) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31_L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs),filter_L12_L21_L13_L31_L13_L31_L12_L21) \n",
    "    x_combo = x_combo + ((1-L12_L21_L13_L31_L13_L31_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L12_L21_L13_L31_L13_L31_L12_L21[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    x_combo_minus = np.zeros(length)\n",
    "\n",
    "    x_combo_minus = x_combo_minus + (s13 + 0.5*(tau13-eps13) + 0.5*(tau12-tau13)) \n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L13) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13[1])*(next_term + np.gradient(next_term,1/f_s)*L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L13_L31) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L13_L31_L12) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L13_L31_L12_L21) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L13_L31_L12_L21_L12) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s13_coeffs + 0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau12_coeffs-tau13_coeffs),filter_L13_L31_L12_L21_L12_L21) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L13_L31_L12_L21_L12_L21_L13) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau13_coeffs-eps13_coeffs) + 0.5*(tau13_coeffs-tau12_coeffs),filter_L13_L31_L12_L21_L12_L21_L13_L31) \n",
    "    x_combo_minus = x_combo_minus + ((1-L13_L31_L12_L21_L12_L21_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L13_L31_L12_L21_L12_L21_L13_L31[2]))\n",
    "\n",
    "    x_combo = x_combo - x_combo_minus\n",
    "    '''\n",
    "    #np.savetxt('x_combo_full.dat',x_combo)\n",
    "    plt.plot(s31,label = 's31')\n",
    "    plt.plot(x_combo,label='x combo')\n",
    "    plt.plot(window*x_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    x_f = np.fft.rfft(window*x_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(x_f),np.imag(x_f)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4cba1e",
   "metadata": {},
   "source": [
    "# TDI Y Channel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_combo_2_0(delay_array):\n",
    "\n",
    "    L23 = nested_delay_application(delay_array,np.array([1]))\n",
    "    L23_L32 = nested_delay_application(delay_array,np.array([1,0]))\n",
    "    L23_L32_L21 = nested_delay_application(delay_array,np.array([1,0,4]))\n",
    "    L23_L32_L21_L12 = nested_delay_application(delay_array,np.array([1,0,4,5]))\n",
    "    L23_L32_L21_L12_L21 = nested_delay_application(delay_array,np.array([1,0,4,5,4]))\n",
    "    L23_L32_L21_L12_L21_L12 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5]))\n",
    "    L23_L32_L21_L12_L21_L12_L23 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5,1]))\n",
    "    L23_L32_L21_L12_L21_L12_L23_L32 = nested_delay_application(delay_array,np.array([1,0,4,5,4,5,1,0]))\n",
    "\n",
    "    L21 = nested_delay_application(delay_array,np.array([4]))\n",
    "    L21_L12 = nested_delay_application(delay_array,np.array([4,5]))\n",
    "    L21_L12_L23 = nested_delay_application(delay_array,np.array([4,5,1]))\n",
    "    L21_L12_L23_L32 = nested_delay_application(delay_array,np.array([4,5,1,0]))\n",
    "    L21_L12_L23_L32_L23 = nested_delay_application(delay_array,np.array([4,5,1,0,1]))\n",
    "    L21_L12_L23_L32_L23_L32 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0]))\n",
    "    L21_L12_L23_L32_L23_L32_L21 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0,4]))\n",
    "    L21_L12_L23_L32_L23_L32_L21_L12 = nested_delay_application(delay_array,np.array([4,5,1,0,1,0,4,5]))\n",
    "\n",
    "\n",
    "    filter_L23 = filters_lagrange_2_0(L23[0])\n",
    "    filter_L23_L32 = filters_lagrange_2_0(L23_L32[0])\n",
    "    filter_L23_L32_L21 = filters_lagrange_2_0(L23_L32_L21[0])\n",
    "    filter_L23_L32_L21_L12 = filters_lagrange_2_0(L23_L32_L21_L12[0])\n",
    "    filter_L23_L32_L21_L12_L21 = filters_lagrange_2_0(L23_L32_L21_L12_L21[0])\n",
    "    filter_L23_L32_L21_L12_L21_L12 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12[0])\n",
    "    filter_L23_L32_L21_L12_L21_L12_L23 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12_L23[0])    \n",
    "    filter_L23_L32_L21_L12_L21_L12_L23_L32 = filters_lagrange_2_0(L23_L32_L21_L12_L21_L12_L23_L32[0])\n",
    "\n",
    "    filter_L21 = filters_lagrange_2_0(L21[0])\n",
    "    filter_L21_L12 = filters_lagrange_2_0(L21_L12[0])\n",
    "    filter_L21_L12_L23 = filters_lagrange_2_0(L21_L12_L23[0])\n",
    "    filter_L21_L12_L23_L32 = filters_lagrange_2_0(L21_L12_L23_L32[0])\n",
    "    filter_L21_L12_L23_L32_L23 = filters_lagrange_2_0(L21_L12_L23_L32_L23[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32_L21 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32_L21[0])\n",
    "    filter_L21_L12_L23_L32_L23_L32_L21_L12 = filters_lagrange_2_0(L21_L12_L23_L32_L23_L32_L21_L12[0])\n",
    "\n",
    "    y_combo = np.zeros(length)\n",
    "    y_combo = y_combo + (s23 + 0.5*(tau23-eps23)) \n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L23) \n",
    "    y_combo = y_combo + ((1-L23[1])*(next_term + np.gradient(next_term,1/f_s)*L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s21_coeffs + 0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau23_coeffs-tau21_coeffs),filter_L23_L32) \n",
    "    y_combo = y_combo + ((1-L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau12_coeffs-eps12_coeffs) + s12_coeffs + 0.5*(tau12_coeffs-eps12_coeffs),filter_L23_L32_L21) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21[2]))\n",
    "\n",
    "    next_term = trim_data((tau21_coeffs-eps21_coeffs) + s21_coeffs,filter_L23_L32_L21_L12) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L23_L32_L21_L12_L21) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L23_L32_L21_L12_L21_L12) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L23_L32_L21_L12_L21_L12_L23) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12_L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs),filter_L23_L32_L21_L12_L21_L12_L23_L32) \n",
    "    y_combo = y_combo + ((1-L23_L32_L21_L12_L21_L12_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L23_L32_L21_L12_L21_L12_L23_L32[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    y_combo_minus = np.zeros(length)\n",
    "\n",
    "    y_combo_minus = y_combo_minus + (s21 + 0.5*(tau21-eps21) + 0.5*(tau23-tau21)) \n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L21) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21[1])*(next_term + np.gradient(next_term,1/f_s)*L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L21_L12) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L21_L12_L23) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L21_L12_L23_L32) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L21_L12_L23_L32_L23) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s21_coeffs + 0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau23_coeffs-tau21_coeffs),filter_L21_L12_L23_L32_L23_L32) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau12_coeffs-eps12_coeffs) + s12_coeffs,filter_L21_L12_L23_L32_L23_L32_L21) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32_L21[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32_L21[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau21_coeffs-eps21_coeffs) + 0.5*(tau21_coeffs-tau23_coeffs),filter_L21_L12_L23_L32_L23_L32_L21_L12) \n",
    "    y_combo_minus = y_combo_minus + ((1-L21_L12_L23_L32_L23_L32_L21_L12[1])*(next_term + np.gradient(next_term,1/f_s)*L21_L12_L23_L32_L23_L32_L21_L12[2]))\n",
    "\n",
    "    y_combo = y_combo - y_combo_minus\n",
    "    \n",
    "    '''\n",
    "    #np.savetxt('y_combo_full.dat',y_combo)\n",
    "    plt.plot(s12,label = 's12_')\n",
    "    plt.plot(y_combo,label='y combo')\n",
    "    plt.plot(window*y_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    y_f = np.fft.rfft(window*y_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(y_f),np.imag(y_f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6b01c",
   "metadata": {},
   "source": [
    "# TDI Z Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_combo_2_0(delay_array):\n",
    "\n",
    "    L31 = nested_delay_application(delay_array,np.array([3]))\n",
    "    L31_L13 = nested_delay_application(delay_array,np.array([3,2]))\n",
    "    L31_L13_L32 = nested_delay_application(delay_array,np.array([3,2,0]))\n",
    "    L31_L13_L32_L23 = nested_delay_application(delay_array,np.array([3,2,0,1]))\n",
    "    L31_L13_L32_L23_L32 = nested_delay_application(delay_array,np.array([3,2,0,1,0]))\n",
    "    L31_L13_L32_L23_L32_L23 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1]))\n",
    "    L31_L13_L32_L23_L32_L23_L31 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1,3]))\n",
    "    L31_L13_L32_L23_L32_L23_L31_L13 = nested_delay_application(delay_array,np.array([3,2,0,1,0,1,3,2]))\n",
    "\n",
    "    L32 = nested_delay_application(delay_array,np.array([0]))\n",
    "    L32_L23 = nested_delay_application(delay_array,np.array([0,1]))\n",
    "    L32_L23_L31 = nested_delay_application(delay_array,np.array([0,1,3]))\n",
    "    L32_L23_L31_L13 = nested_delay_application(delay_array,np.array([0,1,3,2]))\n",
    "    L32_L23_L31_L13_L31 = nested_delay_application(delay_array,np.array([0,1,3,2,3]))\n",
    "    L32_L23_L31_L13_L31_L13 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2]))\n",
    "    L32_L23_L31_L13_L31_L13_L32 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2,0]))\n",
    "    L32_L23_L31_L13_L31_L13_L32_L23 = nested_delay_application(delay_array,np.array([0,1,3,2,3,2,0,1]))\n",
    "\n",
    "\n",
    "    filter_L31 = filters_lagrange_2_0(L31[0])\n",
    "    filter_L31_L13 = filters_lagrange_2_0(L31_L13[0])\n",
    "    filter_L31_L13_L32 = filters_lagrange_2_0(L31_L13_L32[0])\n",
    "    filter_L31_L13_L32_L23 = filters_lagrange_2_0(L31_L13_L32_L23[0])\n",
    "    filter_L31_L13_L32_L23_L32 = filters_lagrange_2_0(L31_L13_L32_L23_L32[0])\n",
    "    filter_L31_L13_L32_L23_L32_L23 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23[0])\n",
    "    filter_L31_L13_L32_L23_L32_L23_L31 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23_L31[0])    \n",
    "    filter_L31_L13_L32_L23_L32_L23_L31_L13 = filters_lagrange_2_0(L31_L13_L32_L23_L32_L23_L31_L13[0])\n",
    "\n",
    "    filter_L32 = filters_lagrange_2_0(L32[0])\n",
    "    filter_L32_L23 = filters_lagrange_2_0(L32_L23[0])\n",
    "    filter_L32_L23_L31 = filters_lagrange_2_0(L32_L23_L31[0])\n",
    "    filter_L32_L23_L31_L13 = filters_lagrange_2_0(L32_L23_L31_L13[0])\n",
    "    filter_L32_L23_L31_L13_L31 = filters_lagrange_2_0(L32_L23_L31_L13_L31[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13_L32 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13_L32[0])\n",
    "    filter_L32_L23_L31_L13_L31_L13_L32_L23 = filters_lagrange_2_0(L32_L23_L31_L13_L31_L13_L32_L23[0])\n",
    "\n",
    "        \n",
    "    z_combo = np.zeros(length)\n",
    "    z_combo = z_combo + (s31 + 0.5*(tau31-eps31)) \n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L31) \n",
    "    z_combo = z_combo + ((1-L31[1])*(next_term + np.gradient(next_term,1/f_s)*L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s32_coeffs + 0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau31_coeffs-tau32_coeffs),filter_L31_L13) \n",
    "    z_combo = z_combo + ((1-L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau23_coeffs-eps23_coeffs) + s23_coeffs + 0.5*(tau23_coeffs-eps23_coeffs),filter_L31_L13_L32) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32[2]))\n",
    "\n",
    "    next_term = trim_data((tau32_coeffs-eps32_coeffs) + s32_coeffs,filter_L31_L13_L32_L23) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L31_L13_L32_L23_L32) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L31_L13_L32_L23_L32_L23) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L31_L13_L32_L23_L32_L23_L31) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23_L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs),filter_L31_L13_L32_L23_L32_L23_L31_L13) \n",
    "    z_combo = z_combo + ((1-L31_L13_L32_L23_L32_L23_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L31_L13_L32_L23_L32_L23_L31_L13[2]))\n",
    "\n",
    "    #BEGIN NEGATIVE\n",
    "    z_combo_minus = np.zeros(length)\n",
    "\n",
    "    z_combo_minus = z_combo_minus + (s32 + 0.5*(tau32-eps32) + 0.5*(tau31-tau32)) \n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L32) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32[1])*(next_term + np.gradient(next_term,1/f_s)*L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs) + s31_coeffs + 0.5*(tau31_coeffs-eps31_coeffs),filter_L32_L23) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L32_L23_L31) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31[2]))\n",
    "\n",
    "    next_term = trim_data((tau31_coeffs-eps31_coeffs) + s31_coeffs,filter_L32_L23_L31_L13) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau13_coeffs-eps13_coeffs) + s13_coeffs,filter_L32_L23_L31_L13_L31) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau31_coeffs-eps31_coeffs) + s32_coeffs + 0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau31_coeffs-tau32_coeffs),filter_L32_L23_L31_L13_L31_L13) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13[2]))\n",
    "\n",
    "    next_term = trim_data((tau23_coeffs-eps23_coeffs) + s23_coeffs,filter_L32_L23_L31_L13_L31_L13_L32) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13_L32[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13_L32[2]))\n",
    "\n",
    "    next_term = trim_data(0.5*(tau32_coeffs-eps32_coeffs) + 0.5*(tau32_coeffs-tau31_coeffs),filter_L32_L23_L31_L13_L31_L13_L32_L23) \n",
    "    z_combo_minus = z_combo_minus + ((1-L32_L23_L31_L13_L31_L13_L32_L23[1])*(next_term + np.gradient(next_term,1/f_s)*L32_L23_L31_L13_L31_L13_L32_L23[2]))\n",
    "\n",
    "    z_combo = z_combo - z_combo_minus\n",
    "    '''\n",
    "    #np.savetxt('z_combo_full.dat',z_combo)\n",
    "    plt.plot(s12,label = 's12')\n",
    "    plt.plot(z_combo,label='z combo')\n",
    "    plt.plot(window*z_combo,label = 'Kaiser windowed')\n",
    "    plt.legend()\n",
    "    plt.show()    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    z_f = np.fft.rfft(window*z_combo,norm='ortho')[indices_f_band]\n",
    "\n",
    "    return [np.real(z_f),np.imag(z_f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277f83d",
   "metadata": {},
   "source": [
    "# Equal-arm Noise Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_equal_arm(f,Sy_OP,Sy_PM):\n",
    "    \n",
    "    a = 16*np.power(np.sin(2*np.pi*f*avg_L),2)*Sy_OP+(8*np.power(np.sin(4*np.pi*f*avg_L),2)+32*np.power(np.sin(2*np.pi*f*avg_L),2))*Sy_PM\n",
    "    b_ = -4*np.sin(2*np.pi*f*avg_L)*np.sin(4*np.pi*f*avg_L)*(4*Sy_PM+Sy_OP)\n",
    "\n",
    "    return 2*a,2*b_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3f814",
   "metadata": {},
   "source": [
    "# $\\log{\\mathcal{L}}$ Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_analytical_equal_arm(x,y,z):\n",
    "\n",
    "\n",
    "\n",
    "    chi_2 = 1/determinant*(A_*(x[0]**2+x[1]**2+y[0]**2+y[1]**2+z[0]**2+z[1]**2) + 2*B_*(x[0]*y[0]+x[1]*y[1]+x[0]*z[0]+x[1]*z[1]+y[0]*z[0]+y[1]*z[1]))\n",
    "\n",
    "\n",
    "    value = -1*np.sum(chi_2) - log_term_factor - np.sum(log_term_determinant)\n",
    "\n",
    "    return value,np.sum(chi_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad939f6f",
   "metadata": {},
   "source": [
    "# Prior Functions for 3 Keplerian Parameters in Keplerian Orbit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1829fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_minit1(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_minit1).all() and (val <= high_minit1).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prior_semi_major(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_semi_major).all() and (val <= high_semi_major).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def prior_omega(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_omega).all()  and (val <= high_omega).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def prior_arg_per(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_arg_per).all()  and (val <= high_arg_per).all() :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def prior_eccentricity(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_eccentricity).all() and (val <= high_eccentricity).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def prior_inclination(val):\n",
    "    val = np.array(val)\n",
    "    if (val >= low_inclination).all() and (val <= high_inclination).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2423e2a",
   "metadata": {},
   "source": [
    "# $\\log{\\mathcal{L}}*$prior function used with zeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d514b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob_fn(state_current):\n",
    "\n",
    "    semi_major = np.array([state_current[0],state_current[1],state_current[2]])\n",
    "    eccentricity = np.array([state_current[3],state_current[4],state_current[5]])\n",
    "    inclination = np.array([state_current[6],state_current[7],state_current[8]])\n",
    "    m_init1 = np.array([state_current[9],state_current[10],state_current[11]])\n",
    "    omega_init =np.array([state_current[12],state_current[13],state_current[14]])\n",
    "    arg_per = np.array([state_current[15],state_current[16],state_current[17]])\n",
    "\n",
    "    delays_in_time =time_dependence(m_init1,semi_major,eccentricity,inclination,omega_init,arg_per)\n",
    "\n",
    "\n",
    "    x_combo = x_combo_2_0(delays_in_time)\n",
    "    y_combo = y_combo_2_0(delays_in_time)\n",
    "    z_combo = z_combo_2_0(delays_in_time)\n",
    "\n",
    "    likelihood,chi_2_here = likelihood_analytical_equal_arm(x_combo,y_combo,z_combo)\n",
    "\n",
    "    prior = prior_minit1(m_init1)*prior_semi_major(semi_major)*prior_omega(omega_init)*prior_arg_per(arg_per)*prior_eccentricity(eccentricity)*prior_inclination(inclination)\n",
    "\n",
    "    return likelihood + np.log(prior)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378bb2b",
   "metadata": {},
   "source": [
    "# RUN SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96559434",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_s = 4\n",
    "sec = 1*3600\n",
    "f_samp = f_s\n",
    "number_n_data = 7 #lagrange filter length\n",
    "number_n = number_n_data\n",
    "p = number_n//2\n",
    "asd_nu = 28.8 # Hz/rtHz\n",
    "\n",
    "\n",
    "f_min = 5.0e-4 # (= 0.0009765625)\n",
    "f_max = 0.1\n",
    "central_freq=281600000000000.0\n",
    "L_arm = 2.5e9\n",
    "avg_L = L_arm/c\n",
    "\n",
    "static=False\n",
    "equalarmlength=False\n",
    "keplerian=False\n",
    "esa=True\n",
    "\n",
    "\n",
    "matrix=True\n",
    "\n",
    "is_tcb = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfe9a4",
   "metadata": {},
   "source": [
    "# Defined by Orbit Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega_1 = np.pi/2.0\n",
    "delta = 5.0/8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ca3d9",
   "metadata": {},
   "source": [
    "# Initial Parameter Values MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c112813",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_per_0 = -np.pi/2.0\n",
    "semi_major_0=ASTRONOMICAL_UNIT\n",
    "m_init1_0 = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adf247",
   "metadata": {},
   "source": [
    "# Load LISA Instrument Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc484b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "\n",
    "if static==True:\n",
    "    data=np.genfromtxt('/Users/jessica/Desktop/Project_2/TDI_2.0/tryer_faster_codes/LISA_Instrument_RR_disable_all_but_laser_lock_six_static_orbits_tps_ppr_orbits_pyTDI_size_mprs_to_file.dat',names=True)\n",
    "\n",
    "elif equalarmlength==True:\n",
    "    data =  np.genfromtxt('/Users/jessica/Desktop/Project_2/TDI_2.0/orbit_files/LISA_Instrument_RR_disable_all_but_laser_lock_six_equalarmlength_orbits_tps_ppr_orbits_pyTDI_size.dat',names=True)\n",
    "elif keplerian==True:\n",
    "    if is_tcb==True:\n",
    "        data = np.genfromtxt('LISA_Instrument_RR_disable_all_but_laser_lock_six_keplerian_orbits_tcb_ltt_orbits_mprs_and_dpprs_to_file_1_hour_NO_AA_filter_NEW.dat',names=True)\n",
    "    else:\n",
    "        data = np.genfromtxt('LISA_Instrument_RR_disable_all_but_laser_lock_six_ESA_orbits_tcb_ltt_orbits_mprs_and_dpprs_to_file_1_hour_4_Hz_NO_AA_filter_NEW.dat',names=True)\n",
    "\n",
    "elif esa==True:\n",
    "    if is_tcb==True:\n",
    "        data = np.genfromtxt(data_dir+'LISA_Instrument_ESA_orbits_tcb_orbits_4_Hz_3600_sec.dat',names=True)\n",
    "    else:\n",
    "        data = np.genfromtxt(data_dir+'LISA_Instrument_ESA_orbits_ppr_orbits_4_Hz_3600_sec.dat',names=True)\n",
    "\n",
    "\n",
    "initial_length = len(data['s31'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229f0b6",
   "metadata": {},
   "source": [
    "# NUMBER OF SAMPLES SKIPPED IN YOUR LISA INSTRUMENT SIMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 0\n",
    "#cut_off=int(1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09819ed7",
   "metadata": {},
   "source": [
    "# $t_i$ for S/C $i \\in \\{1,2,3\\}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#times = np.arange(initial_length)/f_s\n",
    "times = data['time'][cut_off::]\n",
    "times_one = data['time_one'][cut_off::]\n",
    "times_two = data['time_two'][cut_off::]\n",
    "times_three = data['time_three'][cut_off::]\n",
    "\n",
    "\n",
    "'''\n",
    "#for LISA Orbits 2.1 \n",
    "times = data['time'][cut_off::]\n",
    "times_one = times + data['time_one'][cut_off::]\n",
    "times_two = times + data['time_two'][cut_off::]\n",
    "times_three = times + data['time_three'][cut_off::]\n",
    "'''\n",
    "tcb_times = np.array([times_one,times_two,times_three])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ce2e5",
   "metadata": {},
   "source": [
    "# Important: Check your $t_{init}$ from data simulation with print(i.t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46478e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init =13100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdbe1d",
   "metadata": {},
   "source": [
    "# Interferometer measurements $s_{ij}(t)$, $\\tau_{ij}(t)$, $\\varepsilon_{ij}(t)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7915e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s31 = data['s31'][cut_off::]/central_freq\n",
    "s21 = data['s21'][cut_off::]/central_freq\n",
    "s32 = data['s32'][cut_off::]/central_freq\n",
    "s12 = data['s12'][cut_off::]/central_freq\n",
    "s23 = data['s23'][cut_off::]/central_freq\n",
    "s13 = data['s13'][cut_off::]/central_freq\n",
    "\n",
    "\n",
    "tau31 = data['tau31'][cut_off::]/central_freq\n",
    "tau21 = data['tau21'][cut_off::]/central_freq\n",
    "tau12 = data['tau12'][cut_off::]/central_freq\n",
    "tau32 = data['tau32'][cut_off::]/central_freq\n",
    "tau23 = data['tau23'][cut_off::]/central_freq\n",
    "tau13 = data['tau13'][cut_off::]/central_freq\n",
    "\n",
    "eps31 = data['eps31'][cut_off::]/central_freq\n",
    "eps21 = data['eps21'][cut_off::]/central_freq\n",
    "eps12 = data['eps12'][cut_off::]/central_freq\n",
    "eps32 = data['eps32'][cut_off::]/central_freq\n",
    "eps23 = data['eps23'][cut_off::]/central_freq\n",
    "eps13 = data['eps13'][cut_off::]/central_freq\n",
    "\n",
    "\n",
    "\n",
    "length = len(s31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89b7cc",
   "metadata": {},
   "source": [
    "# Required for FDI Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64090d2",
   "metadata": {},
   "source": [
    "## Constant array for calculating delay polynomials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = np.broadcast_to(np.arange(number_n),(length,number_n)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a541859",
   "metadata": {},
   "source": [
    "## Coefficients in Lagrange Time-varying Filter (Pre-Processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36794c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "s32_coeffs = difference_operator_powers(s32)\n",
    "s31_coeffs = difference_operator_powers(s31)\n",
    "s12_coeffs = difference_operator_powers(s12)\n",
    "s13_coeffs = difference_operator_powers(s13)\n",
    "s21_coeffs = difference_operator_powers(s21)\n",
    "s23_coeffs = difference_operator_powers(s23)\n",
    "\n",
    "eps32_coeffs = difference_operator_powers(eps32)\n",
    "eps31_coeffs = difference_operator_powers(eps31)\n",
    "eps12_coeffs = difference_operator_powers(eps12)\n",
    "eps13_coeffs = difference_operator_powers(eps13)\n",
    "eps21_coeffs = difference_operator_powers(eps21)\n",
    "eps23_coeffs = difference_operator_powers(eps23)\n",
    "\n",
    "tau32_coeffs = difference_operator_powers(tau32)\n",
    "tau31_coeffs = difference_operator_powers(tau31)\n",
    "tau12_coeffs = difference_operator_powers(tau12)\n",
    "tau13_coeffs = difference_operator_powers(tau13)\n",
    "tau21_coeffs = difference_operator_powers(tau21)\n",
    "tau23_coeffs = difference_operator_powers(tau23)\n",
    "\n",
    "\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294edec",
   "metadata": {},
   "source": [
    "# Constant Quantities for $\\log{\\mathcal{L}}$ Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data_length = len(s31)\n",
    "\n",
    "\n",
    "window = kaiser(cut_data_length,kaiser_beta(320))\n",
    "\n",
    "f_band = np.fft.rfftfreq(cut_data_length,1/f_s)\n",
    "indices_f_band = np.where(np.logical_and(f_band>=f_min, f_band<=f_max))\n",
    "f_band=f_band[indices_f_band]\n",
    "\n",
    "Sy_PM = S_y_proof_mass_new_frac_freq(f_band)\n",
    "Sy_OP = S_y_OMS_frac_freq(f_band)\n",
    "a,b_ = covariance_equal_arm(f_band,Sy_OP,Sy_PM)\n",
    "\n",
    "#Needed in inverse calculation\n",
    "A_ = a**2 - b_**2\n",
    "B_ = b_**2 - a*b_\n",
    "\n",
    "log_term_factor = 3*np.log(np.pi)\n",
    "determinant = a*A_+2*b_*B_\n",
    "log_term_determinant = np.log(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874bd79",
   "metadata": {},
   "source": [
    "# Uniform Prior Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad515336",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_minit1 = -np.pi\n",
    "high_minit1 = np.pi\n",
    "\n",
    "\n",
    "low_semi_major = 1.493e11 # where LISA Constants is 149597870700.0\n",
    "high_semi_major = 1.496e11 #Estimate from Fig 6 Trajectory Design Paper (for 10 years; way conservative)\n",
    "\n",
    "low_omega = 0.0\n",
    "high_omega = 2.0*np.pi\n",
    "\n",
    "low_arg_per = 0.0\n",
    "high_arg_per = np.pi\n",
    "\n",
    "low_eccentricity = 0.004 # see fig 6 trajectory design paper\n",
    "high_eccentricity = 0.0055\n",
    "\n",
    "low_inclination = 0.39*np.pi/180.0# see fig 6 trajectory design paper\n",
    "high_inclination = 0.6*np.pi/180.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbd867",
   "metadata": {},
   "source": [
    "# Get truth values from elements_from_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_data = np.genfromtxt('elements_from_Cartesian_{0}_Hz_{1}_sec.dat'.format(f_s,sec))\n",
    "\n",
    "\n",
    "initial_state_truth = np.array([elements_data[0],elements_data[1],elements_data[2],elements_data[3],elements_data[4],elements_data[5],elements_data[6],elements_data[7],elements_data[8],elements_data[9],elements_data[10],elements_data[11],elements_data[12],elements_data[13],elements_data[14],elements_data[15],elements_data[16],elements_data[17]])\n",
    "\n",
    "print('initial_state_truth')\n",
    "print(initial_state_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c112fe",
   "metadata": {},
   "source": [
    "# RUN Zeus SAMPLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867be1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nens = 37 # number of ensemble points\n",
    "Nburnin = 100   # number of burn-in samples\n",
    "Nsamples = 100000  # number of final posterior samples\n",
    "\n",
    "\n",
    "initial_state = np.array([np.random.uniform(elements_data[0]-1.0e-1,elements_data[0]+1.0e-1,size=Nens),np.random.uniform(elements_data[1]-1.0e-1,elements_data[1]+1.0e-1,size=Nens),np.random.uniform(elements_data[2]-1.0e-1,elements_data[2]+1.0e-1,size=Nens),np.random.uniform(elements_data[3]-1.0e-9,elements_data[3]+1.0e-9,size=Nens),np.random.uniform(elements_data[4]-1.0e-9,elements_data[4]+1.0e-9,size=Nens),np.random.uniform(elements_data[5]-1.0e-9,elements_data[5]+1.0e-9,size=Nens),\\\n",
    "            np.random.uniform(elements_data[6]-1.0e-9,elements_data[6]+1.0e-9,size=Nens),np.random.uniform(elements_data[7]-1.0e-9,elements_data[7]+1.0e-9,size=Nens),np.random.uniform(elements_data[8]-1.0e-9,elements_data[8]+1.0e-9,size=Nens), np.random.uniform(elements_data[9]-1.0e-9,elements_data[9]+1.0e-9,size=Nens), np.random.uniform(elements_data[10]-1.0e-9,elements_data[10]+1.0e-9,size=Nens), np.random.uniform(elements_data[11]-1.0e-9,elements_data[11]+1.0e-9,size=Nens),\\\n",
    "            np.random.uniform(elements_data[12]-1.0e-9,elements_data[12]+1.0e-9,size=Nens),np.random.uniform(elements_data[13]-1.0e-9,elements_data[13]+1.0e-9,size=Nens),np.random.uniform(elements_data[14]-1.0e-9,elements_data[14]+1.0e-9,size=Nens),\\\n",
    "            np.random.uniform(elements_data[15]-1.0e-9,elements_data[15]+1.0e-9,size=Nens),np.random.uniform(elements_data[16]-1.0e-9,elements_data[16]+1.0e-9,size=Nens),np.random.uniform(elements_data[17]-1.0e-9,elements_data[17]+1.0e-9,size=Nens)])\n",
    "\n",
    "initial_state=initial_state.T\n",
    "ndims = initial_state.shape[1]\n",
    "initial_state = np.vstack([initial_state, initial_state_truth])\n",
    "\n",
    "Nens+=1\n",
    "\n",
    "semi_major_0=np.array([elements_data[0],elements_data[1],elements_data[2]])\n",
    "eccentricity_0 = np.array([elements_data[3],elements_data[4],elements_data[5]])\n",
    "inclination_0 = np.array([elements_data[6],elements_data[7],elements_data[8]])\n",
    "m_init1_0 =np.array([elements_data[9],elements_data[10],elements_data[11]])\n",
    "omega_init_0 = np.array([elements_data[12],elements_data[13],elements_data[14]])\n",
    "arg_per_0 = np.array([elements_data[15],elements_data[16],elements_data[17]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "cb0 = zeus.callbacks.AutocorrelationCallback(ncheck=100, dact=0.01, nact=10, discard=0.5)\n",
    "cb1 = zeus.callbacks.SaveProgressCallback(\"saved_chains_zeus_light_mode_false.h5\", ncheck=100)\n",
    "if __name__ == \"__main__\": \n",
    "    with Pool() as pool:\n",
    "        sampler = zeus.EnsembleSampler(Nens, ndims, target_log_prob_fn,mu=1e3,pool=pool)\n",
    "        sampler.run_mcmc(initial_state, Nsamples, callbacks=[cb0,cb1])\n",
    "        #sampler.run_mcmc(initial_state_begin_here, Nsamples-len(samples))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"--- %s seconds using multiprocessing---\" % (time.time() - start_time))\n",
    "\n",
    "    plt.figure(figsize=(16,1.5*ndims))\n",
    "    for n in range(ndims):\n",
    "        plt.subplot2grid((ndims, 1), (n, 0))\n",
    "        plt.plot(sampler.get_chain()[:,:,n],alpha=0.5)\n",
    "        #plt.axhline(y=mu[n])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    chain = sampler.get_chain(flat=True, discard=2500)\n",
    "    print('Percentiles')\n",
    "    print (np.percentile(chain, [16, 50, 84], axis=0))\n",
    "    print('Mean')\n",
    "    print (np.mean(chain, axis=0))\n",
    "    print('Standard Deviation')\n",
    "    print (np.std(chain, axis=0))\n",
    "\n",
    "    fig, axes = zeus.cornerplot(chain[::100], size=(16,16))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1135ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
